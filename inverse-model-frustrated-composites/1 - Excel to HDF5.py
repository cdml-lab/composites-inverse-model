# -*- coding: utf-8 -*-
"""1- Excel_to_hdf5_ver02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E6oYcpc6gFerAnpI5qMaAeENlKC8ZmUV

# XLSX to HDF5

** Seperating Train/Val/Test data **
1. This notebook takes in one file for inputs and one file for outputs


## Imports
"""

import h5py
import pandas as pd
import numpy as np
import xlrd
import os
import time
import random
import torch

"""## ***Manually insert file names!***"""

# Dataset Name and Paths
dataset_name = "TEST1"

input_files = "C:/Gal_Msc/Dataset/Dataset_Input_" + dataset_name + ".xlsx"
output_files = "C:/Gal_Msc/Dataset/Dataset_Output_" + dataset_name + ".xlsx"
base_dir = "C:/Gal_Msc/Dataset/" + dataset_name + "/"

hdf5_file_path = base_dir + dataset_name + '.h5'

# Size of Samples
size_x = 15
size_y = 20
shape_data = size_x * size_y

# Training Split
split_percentages = [0, 100]  # percentages to split, modify as needed. accommodates different splits
suffixes = ['Train', 'Test']  # suffixes for file names

"""## Separate to Train / Validate / Test functions
* a function for splitting
* runs on inputs and then outputs
"""


# Run on CUDA

if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"CUDA is available. Using {torch.cuda.get_device_name(0)}")
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU")



def split_excel_to_hdf5_old(file_path, split_percentages, suffixes, base_dir, category, hdf5_file_path):
    """
    Splits an Excel file into specified percentages and saves each split as a group in an HDF5 file.

    DOES NOT RANDOMIZE


    Parameters:
    - file_path (str): Path to the input Excel file.
    - split_percentages (list of int): List of percentages to split the sheets. Must sum to 100.
    - suffixes (list of str): List of suffixes for naming the subgroups in HDF5 file (e.g., ['train', 'test']).
    - base_dir (str): Base directory for saving the HDF5 file.
    - category (str): Main group name in the HDF5 file (e.g., 'Features' or 'Labels').
    - hdf5_file_path (str): Path to the output HDF5 file.

    Returns:
    - None
    """
    # Load the Excel file
    xlsx = pd.ExcelFile(file_path)
    worksheets = xlsx.sheet_names
    total_sheets = len(worksheets)

    # Calculate the number of sheets for each split
    split_counts = [int(total_sheets * (split / 100)) for split in split_percentages]

    # Ensure the splits add up to 100%
    if sum(split_counts) != total_sheets:
        split_counts[-1] += total_sheets - sum(split_counts)

    start = 0
    # Create or open the HDF5 file
    with h5py.File(hdf5_file_path, 'a') as h5file:
        # Create the main group (e.g., 'Features' or 'Labels')
        main_group = h5file.create_group(category)
        for idx, count in enumerate(split_counts):
            end = start + count
            # Create the subgroup (e.g., 'train' or 'test')
            sub_group = main_group.create_group(suffixes[idx])
            for sheet in worksheets[start:end]:
                # Read each sheet from the Excel file
                df = pd.read_excel(xlsx, sheet_name=sheet)
                # Ensure all data is converted to strings
                df = df.astype(str)
                # Extract the column headers
                col_headers = df.columns.astype(str).to_list()
                # Convert DataFrame to numpy array and save to HDF5 under the respective subgroup
                dataset = sub_group.create_dataset(sheet, data=df.to_numpy())
                # Save the column headers as an attribute of the dataset
                dataset.attrs['columns'] = col_headers
            print(f"Saved sheets from {start + 1} to {end} in group {category}/{suffixes[idx]}")
            start = end


def split_excel_to_hdf5(file_path, split_indices, suffixes, base_dir, category, hdf5_file_path):
    """
    Splits an Excel file into specified percentages and saves each split as a group in an HDF5 file.

    Parameters:
    - file_path (str): Path to the input Excel file.
    - split_indices (list of list of int): List of indices for each split.
    - suffixes (list of str): List of suffixes for naming the subgroups in HDF5 file (e.g., ['train', 'test']).
    - base_dir (str): Base directory for saving the HDF5 file.
    - category (str): Main group name in the HDF5 file (e.g., 'Features' or 'Labels').
    - hdf5_file_path (str): Path to the output HDF5 file.

    Returns:
    - None
    """
    # Load the Excel file
    xlsx = pd.ExcelFile(file_path)
    worksheets = xlsx.sheet_names

    # Ensure the directory for the HDF5 file exists
    os.makedirs(os.path.dirname(hdf5_file_path), exist_ok=True)

    # Create or open the HDF5 file
    with h5py.File(hdf5_file_path, 'a') as h5file:
        # Create the main group (e.g., 'Features' or 'Labels')
        main_group = h5file.create_group(category)
        for idx, indices in enumerate(split_indices):
            # Create the subgroup (e.g., 'train' or 'test')
            sub_group = main_group.create_group(suffixes[idx])
            for i in indices:
                sheet = worksheets[i]
                # Read each sheet from the Excel file
                df = pd.read_excel(xlsx, sheet_name=sheet)
                # Ensure all data is converted to strings
                df = df.astype(str)
                # Extract the column headers
                col_headers = df.columns.astype(str).to_list()
                # Convert DataFrame to numpy array and save to HDF5 under the respective subgroup
                dataset = sub_group.create_dataset(sheet, data=df.to_numpy())
                # Save the column headers as an attribute of the dataset
                dataset.attrs['columns'] = col_headers
            print(f"Saved sheets in group {category}/{suffixes[idx]} : {indices} ")


def generate_shuffled_indices(total_sheets, split_percentages):
    indices = list(range(total_sheets))
    random.shuffle(indices)

    split_counts = [int(total_sheets * (split / 100)) for split in split_percentages]
    if sum(split_counts) != total_sheets:
        split_counts[-1] += total_sheets - sum(split_counts)

    split_indices = []
    start = 0
    for count in split_counts:
        end = start + count
        split_indices.append(indices[start:end])
        start = end

    return split_indices


"""## Run the split"""

# Generate the split indices once
xlsx_features = pd.ExcelFile(output_files)
total_sheets = len(xlsx_features.sheet_names)
split_indices = generate_shuffled_indices(total_sheets, split_percentages)

print(split_indices)

# Run the split for both inputs and outputs
for category, file_path in zip(['Labels', 'Features'], [input_files, output_files]):
    if os.path.isfile(file_path) and file_path.endswith('.xlsx'):  # Check if it's a file and an Excel file
        # Run the split
        split_excel_to_hdf5(file_path, split_indices, suffixes, base_dir, category, hdf5_file_path)

# prompt: read the hdf5 file in hdf5_file_path and display it's structure, metadata of groups/datasets and how many dataset each group has

import h5py

with h5py.File(hdf5_file_path, 'r') as h5file:
    # Print the structure of the HDF5 file
    print("Structure:")
    for key in h5file.keys():
        print(f"- {key}")

    # Print the metadata of each group
    print("\nMetadata:")
    for group_name, group in h5file.items():
        print(f"- Group: {group_name}")
        print(f"  Attributes:")
        for attr_name, attr_value in group.attrs.items():
            print(f"    - {attr_name}: {attr_value}")
        print(f"  Datasets:")
        for dataset_name in group:
            print(f"    - {dataset_name}")

    # Print the number of datasets in each group
    print("\nNumber of datasets in each group:")
    for group_name, group in h5file.items():
        print(f"- {group_name}: {len(group)}")
