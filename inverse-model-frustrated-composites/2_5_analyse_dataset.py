# -*- coding: utf-8 -*-
"""2.5- Analyse Dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfC0Q0vWN-0SBnOxOsOpaA67FunHHlA7
"""
# Import Libraries
import h5py
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use a non-interactive backend
import matplotlib.pyplot as plt
import pandas as pd
import torch
import os

print("PyTorch version:", torch.__version__)
print("CUDA version:", torch.version.cuda)
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print(f"Using GPU: {torch.cuda.get_device_name(0)}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


og_dataset_name = '30-35'
dataset_name = '30-35_Normal'
patches = '_Reshaped'
plot_correlations = False

feature_titles = {
    0: "Movement Vector Length",
    1: "Max Curvature Length",
    2: "Min Curvature Length",
    3: "Location X",
    4: "Location Y",
    5: "Location Z",
    6: "MVD-X",
    7: "MVD-Y",
    8: "MVD-Z",
    9: "MaCD-X",
    10: "MaCD-Y",
    11: "MaCD-Z",
    12: "MiCD-X",
    13: "MiCD-Y",
    14: "MiCD-Z",
    15: "No-X",
    16: "No-Y",
    17: "No-Z",
    18: "U-X",
    19: "U-Y",
    20: "U-Z",
    21: "V-X",
    22: "V-Y",
    23: "V-Z",
    25: "Angle"
}

feature_titles = {
    1: "Max Curvature Length",
    2: "Min Curvature Length",
    3: "MaCD-X",
    4: "MaCD-Y",
    5: "MaCD-Z",
    6: "MiCD-X",
    7: "MiCD-Y",
    8: "MiCD-Z",
    9: "No-X",
    10: "No-Y",
    11: "No-Z",
    12: "U-X",
    13: "U-Y",
    14: "U-Z",
    15: "V-X",
    16: "V-Y",
    17: "V-Z",
    25: "Angle"
}




# Set dataset files
features_file_path = "C:/Gal_Msc/Ipublic-repo/frustrated-composites-dataset/" + og_dataset_name + '/' + dataset_name + '_Features' + patches + '.h5'
labels_file_path = "C:/Gal_Msc/Ipublic-repo/frustrated-composites-dataset/" + og_dataset_name + '/' + dataset_name + '_Labels' + patches + '.h5'


#labels_file_path = "C:/Gal_Msc/Ipublic-repo/frustrated-composites-dataset/" + og_dataset_name + '/' + dataset_name + '_Labels_Reshaped.h5'
#features_file_path = "C:/Gal_Msc/Ipublic-repo/frustrated-composites-dataset/" + og_dataset_name + '/' + dataset_name + '_Features_Reshaped.h5'

# Read Labels HDF5 File
with h5py.File(labels_file_path, 'r') as labels_file:
    labels_train = labels_file['Labels/Train']
    labels_test = labels_file['Labels/Test']

    # Ensure all elements are at least 1D arrays
    labels_train_data = [np.atleast_1d(labels_train[key][()]) for key in labels_train.keys()]
    labels_test_data = [np.atleast_1d(labels_test[key][()]) for key in labels_test.keys()]

    labels_train_flat = np.concatenate(labels_train_data)
    labels_test_flat = np.concatenate(labels_test_data)

    labels_all = np.concatenate((labels_train_flat, labels_test_flat))

# Read Features HDF5 File
with h5py.File(features_file_path, 'r') as features_file:
    features_train = features_file['Features/Train']
    features_test = features_file['Features/Test']

    features_train_data = [features_train[key][()] for key in features_train.keys()]
    features_test_data = [features_test[key][()] for key in features_test.keys()]

    features_train_flat = np.concatenate(features_train_data)
    features_test_flat = np.concatenate(features_test_data)

    features_all = np.concatenate((features_train_flat, features_test_flat))

# Create a directory to save plots
plot_dir = "plots"
if not os.path.exists(plot_dir):
    os.makedirs(plot_dir)
scatter_plot_dir = "plots/correlations"
if not os.path.exists(scatter_plot_dir):
    os.makedirs(scatter_plot_dir)


# 1. Distribution of Labels
unique, counts = np.unique(labels_all, return_counts=True)
plt.bar(unique, counts)
plt.xlabel('Label')
plt.ylabel('Frequency')
plt.title('Distribution of Labels')
plt.savefig(os.path.join(plot_dir, 'distribution_labels.png'))
plt.close()

# 1. Distribution of Labels for Train Data
unique_train, counts_train = np.unique(labels_train_flat, return_counts=True)
plt.bar(unique_train, counts_train)
plt.xlabel('Label')
plt.ylabel('Frequency')
plt.title('Distribution of Train Labels')
plt.savefig(os.path.join(plot_dir, 'distribution_train_labels.png'))
plt.show()
plt.close()

# 1. Distribution of Labels for Test Data
unique_test, counts_test = np.unique(labels_test_flat, return_counts=True)
plt.bar(unique_test, counts_test)
plt.xlabel('Label')
plt.ylabel('Frequency')
plt.title('Distribution of Test Labels')
plt.savefig(os.path.join(plot_dir, 'distribution_test_labels.png'))
plt.show()
plt.close()

# 2. Statistics for Each Feature Column
features_combined = np.vstack(features_all)
column_stats = {
    'max': np.max(features_combined, axis=0),
    'min': np.min(features_combined, axis=0),
    'median': np.median(features_combined, axis=0),
    'mean': np.mean(features_combined, axis=0)
}

print("Column statistics:")
for stat, values in column_stats.items():
    print(f"{stat.capitalize()}: {values}")

# 3. Statistics for Each Feature Column in a Structured Format
column_stats_df = pd.DataFrame(column_stats)
print(column_stats_df)

# 2. Statistics for Each Feature Column in Train Data
features_train_combined = np.vstack(features_train_flat)
column_stats_train = {
    'max': np.max(features_train_combined, axis=0),
    'min': np.min(features_train_combined, axis=0),
    'median': np.median(features_train_combined, axis=0),
    'mean': np.mean(features_train_combined, axis=0)
}

# Statistics for Each Feature Column in a Structured Format
print("Train Column statistics:")
column_stats_df = pd.DataFrame(column_stats_train)
print(column_stats_df)

# 3. Statistics for Each Feature Column in Test Data
features_test_combined = np.vstack(features_test_flat)
column_stats_test = {
    'max': np.max(features_test_combined, axis=0),
    'min': np.min(features_test_combined, axis=0),
    'median': np.median(features_test_combined, axis=0),
    'mean': np.mean(features_test_combined, axis=0)
}

# Statistics for Each Feature Column in a Structured Format
print("Test Column statistics:")
column_stats_df = pd.DataFrame(column_stats_test)
print(column_stats_df)

# 4. Distribution of Feature Values
num_columns = features_combined.shape[1]
for i in range(num_columns):
    plt.hist(features_combined[:, i], bins=50, alpha=0.75, label=f'Column {i+1}')
    plt.xlabel('Feature Value')
    plt.ylabel('Frequency')
    plt.title(f'Distribution of Feature Values - Column {i+1}')

    plt.legend()
    plt.savefig(os.path.join(plot_dir, f'distribution_feature_values_column_{i+1}.png'))
    plt.close()


# 5. Histogram of Feature Samples per Range (Per Channel) with Bin Annotations
num_channels = features_combined.shape[1]
bins = 50  # Number of bins in the histogram

for i in range(num_channels):
    channel_data = features_combined[:, i]

    # Create histogram
    plt.figure(figsize=(20, 20))  # Enlarged plot size
    counts, bin_edges, _ = plt.hist(
        channel_data, bins=bins, alpha=0.75, color='blue', edgecolor='black'
    )
    plt.xlabel('Feature Value')
    plt.ylabel('Sample Count')
    plt.title(f'Histogram of Feature Samples - Channel {i}')
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    # Annotate counts above each bin
    for count, bin_edge in zip(counts, bin_edges[:-1]):
        plt.text(
            bin_edge + (bin_edges[1] - bin_edges[0]) / 2,  # Center of the bin
            count + 0.5,  # Slightly above the bar
            str(int(count)),
            ha='center',
            va='bottom',
            fontsize=9,
            color='black'
        )

    # Save and close plot
    plt.savefig(os.path.join(plot_dir, f'histogram_feature_samples_channel_{i}.png'))
    plt.close()

# 4. Distribution of Feature Values for Train Data
num_columns_train = features_train_combined.shape[1]
for i in range(num_columns_train):
    plt.hist(features_train_combined[:, i], bins=50, alpha=0.75, label=f'Column {i+1}')
    plt.xlabel('Feature Value')
    plt.ylabel('Frequency')
    plt.title(f'Distribution of Train Feature Values - Column {i}')
    plt.legend()
    plt.savefig(os.path.join(plot_dir, f'distribution_train_feature_values_column_{i}.png'))
    plt.close()

# 4. Distribution of Feature Values for Test Data
num_columns_test = features_test_combined.shape[1]
for i in range(num_columns_test):
    plt.hist(features_test_combined[:, i], bins=50, alpha=0.75, label=f'Column {i+1}')
    plt.xlabel('Feature Value')
    plt.ylabel('Frequency')
    plt.title(f'Distribution of Test Feature Values - Column {i+1}')
    plt.legend()
    plt.savefig(os.path.join(plot_dir, f'distribution_test_feature_values_column_{i+1}.png'))
    plt.close()

# 5. Correlation plots

if plot_correlations:

    # 5.1. Number of features
    num_features = features_combined.shape[1]
    print(f"Number of features: {num_features}")

    # 5.2. Calculate the number of scatter plots
    num_feature_to_feature_plots = num_features * (num_features - 1) // 2  # nC2
    num_feature_to_label_plots = num_features  # One for each feature vs. labels
    total_plots = num_feature_to_feature_plots + num_feature_to_label_plots
    print(f"Total scatter plots needed: {total_plots}")

    # 5.3. Function to create and save scatter plots
    # Example of using the dictionary in the title generation
    def create_scatter_plot(x_data, y_data, x_index, y_index, save_name):
        if x_data is None or y_data is None or len(x_data) == 0 or len(y_data) == 0:
            print(f"Skipping plot for Feature {x_index} vs. Feature {y_index} due to invalid data.")
            return
        x_title = feature_titles.get(x_index, f"Feature {x_index + 1}")
        y_title = feature_titles.get(y_index, f"Feature {y_index + 1}")

        plt.figure(figsize=(15, 15))
        plt.scatter(x_data, y_data, alpha=0.5, s=1)
        plt.xlabel(x_title)
        plt.ylabel(y_title)
        plt.title(f"{x_title} vs. {y_title}")
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.savefig(save_name)
        plt.close()

    # 5.6. Generate scatter plots for feature-to-label correlations
    for i in range(num_features):
        x_data = features_combined[:, i]
        y_data = labels_all
        feature_title = feature_titles.get(i, f"Feature {i+1}")
        save_name = os.path.join(
            scatter_plot_dir,
            f"{feature_title.replace(' ', '_').replace('-', '_')}_vs_label.png"
        )
        create_scatter_plot(
            x_data, y_data,
            x_index=i,
            y_index=25,  # Labels don't have an index
            save_name=save_name
        )

    # 5.4. Generate scatter plots for feature-to-feature correlations
    for i in range(num_features):
        for j in range(i + 1, num_features):
            x_data = features_combined[:, i]
            y_data = features_combined[:, j]
            x_title = feature_titles.get(i, f"Feature {i+1}")
            y_title = feature_titles.get(j, f"Feature {j+1}")
            save_name = os.path.join(
                scatter_plot_dir,
                f"{x_title.replace(' ', '_').replace('-', '_')}_vs_{y_title.replace(' ', '_').replace('-', '_')}.png"
            )
            create_scatter_plot(
                x_data, y_data,
                x_index=i,
                y_index=j,
                save_name=save_name
            )

    print("Scatter plots for correlations have been generated and saved.")
else:
    print("not plotting correlations")
